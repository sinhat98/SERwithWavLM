{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgVzewPGfmZj"
   },
   "outputs": [],
   "source": [
    "# ライブラリインポート\n",
    "import torch, torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchemotion.datasets.EmodbDataset import EmodbDataset\n",
    "from torchemotion.datasets.IemocapDataset import IemocapDataset\n",
    "from transformers import Wav2Vec2Processor, WavLMModel, WavLMForSequenceClassification, WavLMConfig #, WavLMForCTC\n",
    "from IPython.display import Audio, display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "# model\n",
    "class SERwithWavLM(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_labels):\n",
    "        super().__init__()\n",
    "        self.wavlm_config = WavLMConfig(pretrained_model)\n",
    "        self.wavlm_config.update({'num_labels':num_labels, 'use_weighted_layer_sum':True})\n",
    "        self.wavlm = WavLMForSequenceClassification.from_pretrained(pretrained_model, config=self.wavlm_config)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.wavlm(**inputs[0], labels=inputs[1]) \n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "# initialization of weight    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        # Liner層の初期化\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# count parameters of model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# plot dataset's info about emotion and length of waveform\n",
    "def plot_data(dataset):\n",
    "    emotions = list()\n",
    "    lengths = list()\n",
    "    for i in range(len(dataset)):\n",
    "        data = dataset[i]\n",
    "        emotions.append(int(data['emotion']))\n",
    "        lengths.append(data['waveform'].size(-1))\n",
    "\n",
    "    df_emo = pd.DataFrame(emotions, columns=['emotion'])\n",
    "\n",
    "    fig, ax = plt.subplots(2,1)\n",
    "    ax1, ax2 = ax\n",
    "    sns.countplot(x='emotion', data=df_emo, ax=ax1)\n",
    "    ax2.hist(lengths)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return emotions, lengths\n",
    "\n",
    "# straitified by emotion\n",
    "def make_tar_val_dataset(dataset):\n",
    "    emotions = [int(dataset[i]['emotion']) for i in range(len(dataset))]\n",
    "\n",
    "    train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, stratify=emotions, random_state=42)\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "    emotions_train = [int(train_dataset.__getitem__(i)['emotion']) for i in range(len(train_dataset))]\n",
    "    plt.hist(emotions, label='all')\n",
    "    plt.hist(emotions_train, label='train')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# collate_fn used in dataloader\n",
    "def collate_fn(batch):\n",
    "    waveforms, targets = [], []\n",
    "\n",
    "    for data in batch:\n",
    "        waveforms += [data['waveform'].numpy().flatten()]\n",
    "        targets += [torch.tensor(int(data['emotion']))]\n",
    "\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return waveforms, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Split Dataset\n",
    "[EmoDB](https://www.kaggle.com/datasets/piyushagni5/berlin-database-of-emotional-speech-emodb)や[IEMOCAP](https://sail.usc.edu/iemocap/)のデータセットをダウンロードしてからデータ[torchemotion](https://github.com/alanwuha/torchemotion)を使って読み込む\n",
    "\n",
    "データの分割は感情ラベルが均衡になるように\n",
    "\n",
    "`train_size : test_size = 8 : 2`\n",
    "\n",
    "で分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IEMOCAP\n",
    "data_dir = 'Iemocap_data_dir'\n",
    "dataset = IemocapDataset(root=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emodb\n",
    "data_dir = 'Emodb_data_dir'\n",
    "dataset = IemocapDataset(root=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staratified by emotion\n",
    "emotions = [int(emodb.__getitem__(i)['emotion']) for i in range(len(emodb))]\n",
    "train_indices, val_indices = train_test_split(list(range(len(emotions))), test_size=0.2, stratify=emotions, random_state=seed)\n",
    "train_dataset = torch.utils.data.Subset(emodb, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(emodb, val_indices)\n",
    "\n",
    "# ラベルが均衡になっているか確認\n",
    "emotions_train = [int(train_dataset.__getitem__(i)['emotion'])-1 for i in range(len(train_dataset))]\n",
    "plt.hist(emotions, label='all')\n",
    "plt.hist(emotions_train, label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- 感情分類用：[WavLMForSequenceClassification](https://huggingface.co/docs/transformers/model_doc/wavlm#transformers.WavLMForSequenceClassification)\n",
    "- 音声データの前処理： [Wav2Vec2Processor](https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2Processor)\n",
    "\n",
    "`WavLm`のAttentin機構を利用するためにバッチデータを`Wav2Vec2Processor`で処理してからモデルに入力する。\n",
    "\n",
    "これらの事前学習モデルとして[patrickvonplaten/wavlm-libri-clean-100h-base-plus](https://huggingface.co/patrickvonplaten/wavlm-libri-clean-100h-base-plus)を使用した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processorとmodelの読み込み例\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\") # 前処理\n",
    "model = WavLMForSequenceClassification.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\", config=wavlm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders_dict, optimizer, scheduler, num_epochs, log_interval=10):\n",
    "    \n",
    "    # 高速化\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    log_intervals = 10\n",
    "    pbar_update = 1 / sum([len(v) for v in dataloaders_dict.values()])\n",
    "    \n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\")\n",
    "    \n",
    "    n_step = 0\n",
    "    with tqdm(total=num_epochs) as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  \n",
    "                else:\n",
    "                    model.eval()   \n",
    "                epoch_loss = 0.0  \n",
    "                epoch_corrects = 0\n",
    "                # データローダーからミニバッチを取り出すループ\n",
    "                for step, (data, target) in enumerate(dataloaders_dict[phase]):\n",
    "                    \n",
    "                    # GPUが使えるならGPUにデータを送る\n",
    "                    inputs = processor(data, sampling_rate=16000,  return_tensors='pt', padding=True)\n",
    "                    \n",
    "                    # DataParallelでも動くように入力をすべて同じdeviceに送る\n",
    "                    input_tensor = torch.stack((inputs['input_values'], inputs['attention_mask'])).to(device)\n",
    "                    \n",
    "                    # wavlmのモデルに入力する辞書を作成\n",
    "                    input_dict = {}\n",
    "                    for i, k in enumerate(inputs.keys()):\n",
    "                        input_dict[k] = input_tensor[i]\n",
    "                        \n",
    "                    target = target.to(device)\n",
    "                    inputs = (input_dict, target) # モデルの入力に形式を合わせるためにタプルを作成\n",
    "                    \n",
    "                    # optimizerを初期化\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # 順伝搬（forward）計算\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        logits, loss = model(inputs)\n",
    "                        loss = loss.mean(dim=-1) # deviceごとに平均をとる\n",
    "                        preds = torch.argmax(logits, dim=-1)  # ラベルを予測\n",
    "\n",
    "                        # 訓練時はバックプロパゲーション\n",
    "                        if phase == 'train':\n",
    "                            n_step += len(data)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            if scheduler is not None:\n",
    "                                scheduler.step()\n",
    "                            loss_log = loss.item()\n",
    "                            del loss\n",
    "                            if step % log_interval == 0:\n",
    "                                print(f\"Train Epoch: {epoch} [{step * len(data)}/{len(dataloaders_dict[phase].dataset)} ({100. * step / len(dataloaders_dict[phase]):.0f}%)]\\tLoss: {loss_log:.6f}\")\n",
    "                            \n",
    "                        # else:\n",
    "                            # print(preds.to('cpu').detach().numpy()) 推論結果を表示\n",
    "                       \n",
    "                        epoch_loss += loss_log * len(data)\n",
    "                        epoch_corrects += preds.squeeze().eq(target).sum().item()\n",
    "                        \n",
    "                        pbar.update(pbar_update)\n",
    "                    \n",
    "                # epochごとのlossと正解率\n",
    "                epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "                epoch_acc = epoch_corrects / len(dataloaders_dict[phase].dataset)\n",
    "               \n",
    "                print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                               phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOqOBe_AoQkK"
   },
   "outputs": [],
   "source": [
    "# デバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 設定\n",
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "pretrained_model = \"patrickvonplaten/wavlm-libri-clean-100h-base-plus\"\n",
    "num_labels = 4\n",
    "\n",
    "# データローダー作成\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "dataloaders_dict = {'train': train_loader, 'val': test_loader}\n",
    "\n",
    "# モデルの初期化\n",
    "model = SERwithWavLM(pretrained_model, num_labels)\n",
    "model.wavlm.classifier.apply(weights_init)\n",
    "\n",
    "# モデルの並列化\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    prams = model.module.parameters()\n",
    "else:\n",
    "    params = model.parameters()\n",
    "model.to(device)\n",
    "\n",
    "# optimizerとschedulerの作成\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.9)\n",
    "\n",
    "# 訓練と評価\n",
    "model = train_model(model, dataloaders_dict, optimizer, scheduler, num_epochs, log_interval=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wavlm_summary.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10bc24d58dd64baf9875951175d53cb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13593a06989240bd8d2cca1d13d302c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16931946ca934132bc47219683486303": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "344d4d40846c48c5b23d1f2f004a6a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f605ea8772394995828669527c9e39c7",
      "placeholder": "​",
      "style": "IPY_MODEL_deb1de98e25f4fb798c9d721e4dcca04",
      "value": " 0.8382352941176459/10 [00:59&lt;05:49, 38.20s/it]"
     }
    },
    "7a2585dcff9e46d2b3e429cdfe15251b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10bc24d58dd64baf9875951175d53cb7",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13593a06989240bd8d2cca1d13d302c7",
      "value": 0.8382352941176459
     }
    },
    "96817ccf7f694652a9ee52704bc833df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c25575c795c498dad30ddb60a54992f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2aad960f4e147c39bbf4e3486ae8abf",
       "IPY_MODEL_7a2585dcff9e46d2b3e429cdfe15251b",
       "IPY_MODEL_344d4d40846c48c5b23d1f2f004a6a2c"
      ],
      "layout": "IPY_MODEL_16931946ca934132bc47219683486303"
     }
    },
    "c2843e7055024ca59738182107150ae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2aad960f4e147c39bbf4e3486ae8abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96817ccf7f694652a9ee52704bc833df",
      "placeholder": "​",
      "style": "IPY_MODEL_c2843e7055024ca59738182107150ae3",
      "value": "  8%"
     }
    },
    "deb1de98e25f4fb798c9d721e4dcca04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f605ea8772394995828669527c9e39c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
