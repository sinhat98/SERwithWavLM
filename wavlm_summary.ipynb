{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KgVzewPGfmZj"
   },
   "outputs": [],
   "source": [
    "# ライブラリインポート\n",
    "import torch, torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchemotion.datasets.EmodbDataset import EmodbDataset\n",
    "from torchemotion.datasets.IemocapDataset import IemocapDataset\n",
    "from transformers import Wav2Vec2Processor, WavLMModel, WavLMForSequenceClassification, WavLMConfig #, WavLMForCTC\n",
    "from IPython.display import Audio, display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaWgWuBRnXJR"
   },
   "source": [
    "[Emodb dataset](https://www.kaggle.com/datasets/piyushagni5/berlin-database-of-emotional-speech-emodb)\n",
    "\n",
    "kaggleに上がっていたのでそこから入手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t     'SER_ review.pptx'  torchemotion  WavLM.ipynb\n",
      "EmoDB.zip\t     SER_with_cnn.ipynb  utils\t       wavlm_summary.ipynb\n",
      "make_download.ipynb  speechbrain\t wandb\n",
      "SER_model.ipynb      speechbrain.ipynb\t wavlm\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './data/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_script02_2/Ses01M_script02_2_F000.wav',\n",
       " 'waveform': tensor([[-0.0034, -0.0037, -0.0033,  ..., -0.0053, -0.0050, -0.0036]]),\n",
       " 'sample_rate': 16000,\n",
       " 'emotion': 7.0,\n",
       " 'activation': 4.0,\n",
       " 'valence': 2.0,\n",
       " 'dominance': 2.5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IEMOCAP\n",
    "Iemocap = IemocapDataset(root='./data/IEMOCAP_full_release',\n",
    "                        emotions=['ang', 'hap', 'exc', 'sad', 'fru', 'fea', 'sur', 'neu', 'xxx'])\n",
    "Iemocap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Iemocap)):\n",
    "    print(Iemocap[i]['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puEpnXMH9Muo",
    "outputId": "f41ea0c2-dbb7-41ee-e293-9cae547750b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'waveform': tensor([[ 0.0000, -0.0001,  0.0000,  ..., -0.0038, -0.0040, -0.0042]]),\n",
       " 'sample_rate': 16000,\n",
       " 'emotion': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emodb = EmodbDataset(root='data/EmoDB/')\n",
    "emodb.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "i0NBaUXv94HV",
    "outputId": "737ea95b-f17a-4eb9-ec64-ff85d1dfa726"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "num_labels=7\n",
    "emotions = list()\n",
    "lengths = list()\n",
    "for i in range(len(emodb)):\n",
    "    emotions.append(int(emodb.__getitem__(i)['emotion']-1))\n",
    "    lengths.append(emodb.__getitem__(i)['waveform'].size(-1))\n",
    "\n",
    "df_emo = pd.DataFrame(emotions, columns=['emotion'])\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax1, ax2 = ax\n",
    "sns.countplot(x='emotion', data=df_emo, ax=ax1)\n",
    "ax2.hist(lengths)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_data(dataset):\n",
    "    emotions = list()\n",
    "    lengths = list()\n",
    "    for i in range(len(subset)):\n",
    "        data = subset[i]\n",
    "        emotions.append(int(data['emotion']))\n",
    "        lengths.append(data['waveform'].size(-1))\n",
    "\n",
    "    df_emo = pd.DataFrame(emotions, columns=['emotion'])\n",
    "\n",
    "    fig, ax = plt.subplots(2,1)\n",
    "    ax1, ax2 = ax\n",
    "    sns.countplot(x='emotion', data=df_emo, ax=ax1)\n",
    "    ax2.hist(lengths)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return emotions, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gs/hs1/tga-i/otake.s.ad/SER/torchemotion/datasets/IemocapDataset.py:58: FutureWarning: Could not cast to float32, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  self.df = pd.DataFrame(data, columns=['start', 'end', 'file', 'emotion', 'activation', 'valence', 'dominance', 'session', 'script_impro', 'gender', 'utterance'], dtype=np.float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "labels = ['ang', 'hap', 'sad', 'neu']\n",
    "Iemocap = IemocapDataset(root='./data/IEMOCAP_full_release', emotions=labels)\n",
    "num_labels = 4\n",
    "emotions = list()\n",
    "lengths = list()\n",
    "for i in range(len(Iemocap)):\n",
    "    data = Iemocap[i]\n",
    "    '''if data['emotion'] == 7.0:\n",
    "        data['emotion'] = 4.0'''\n",
    "    emotions.append(int(data['emotion']))\n",
    "    lengths.append(data['waveform'].size(-1))\n",
    "\n",
    "df_emo = pd.DataFrame(emotions, columns=['emotion'])\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax1, ax2 = ax\n",
    "sns.countplot(x='emotion', data=df_emo, ax=ax1)\n",
    "ax2.hist(lengths)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "7          1701\n",
       "0          1096\n",
       "3          1060\n",
       "1           592\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_length(dataset, labels, lthresh=250000):\n",
    "    emo_count = {}\n",
    "    for l in labels:\n",
    "        emo_count[l] = 0\n",
    "    for i in range(len(dataset)):\n",
    "        data = dataset[i]\n",
    "        if data['waveform'].size(-1) < lthresh:\n",
    "            emo_count[int(data['emotion'])] += 1\n",
    "    return min(list(emo_count.values())), emo_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gs/hs1/tga-i/otake.s.ad/SER/torchemotion/datasets/IemocapDataset.py:58: FutureWarning: Could not cast to float32, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  self.df = pd.DataFrame(data, columns=['start', 'end', 'file', 'emotion', 'activation', 'valence', 'dominance', 'session', 'script_impro', 'gender', 'utterance'], dtype=np.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(468, {0: 871, 1: 468, 3: 758, 7: 1444})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['ang', 'hap', 'sad', 'neu']\n",
    "Iemocap = IemocapDataset(root='./data/IEMOCAP_full_release', emotions=labels)\n",
    "filter_length(Iemocap, labels = [0, 1, 3, 7], lthresh=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gs/hs1/tga-i/otake.s.ad/SER/torchemotion/datasets/IemocapDataset.py:58: FutureWarning: Could not cast to float32, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  self.df = pd.DataFrame(data, columns=['start', 'end', 'file', 'emotion', 'activation', 'valence', 'dominance', 'session', 'script_impro', 'gender', 'utterance'], dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_emotion is reached at MAX\n",
      "3_emotion is reached at MAX\n",
      "0_emotion is reached at MAX\n",
      "1_emotion is reached at MAX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'path': './data/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_script02_2/Ses01M_script02_2_F000.wav',\n",
       " 'waveform': tensor([[-0.0034, -0.0037, -0.0033,  ..., -0.0053, -0.0050, -0.0036]]),\n",
       " 'sample_rate': 16000,\n",
       " 'emotion': 3.0,\n",
       " 'activation': 4.0,\n",
       " 'valence': 2.0,\n",
       " 'dominance': 2.5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['ang', 'hap', 'sad', 'neu']\n",
    "Iemocap = IemocapDataset(root='./data/IEMOCAP_full_release', emotions=labels)\n",
    "\n",
    "# lthresh未満の音声の均衡クラスラベルデータセットを作成\n",
    "num_labels = 4\n",
    "lthresh = 100000\n",
    "\n",
    "emo_dict = {}\n",
    "emo_dict_flag = {}\n",
    "labels = [0, 1, 3, 7]\n",
    "MAX, _ = filter_length(Iemocap, labels=[0,1,3,7], lthresh=lthresh)\n",
    "for label in labels:\n",
    "    emo_dict[label] = 0\n",
    "    emo_dict_flag[label] = True\n",
    "subset = []\n",
    "for i in range(len(Iemocap)):\n",
    "    data = Iemocap[i]\n",
    "    emotion = int(data['emotion'])\n",
    "    if data['waveform'].size(-1) < lthresh:\n",
    "        if emo_dict_flag[emotion]:\n",
    "            #pdb.set_trace()\n",
    "            if emotion == 3:\n",
    "                data['emotion'] = 2.0\n",
    "            elif emotion == 7:\n",
    "                data['emotion'] = 3.0\n",
    "            subset.append(data)\n",
    "            emo_dict[emotion] += 1\n",
    "            if emo_dict[emotion] == MAX:\n",
    "                print(f'{emotion}_emotion is reached at MAX')\n",
    "                emo_dict_flag[emotion] = False\n",
    "        if sum(list(emo_dict_flag.values())) == 0:\n",
    "            break\n",
    "subset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions, lengths = plot_data(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    592\n",
       "1    592\n",
       "2    592\n",
       "3    592\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(emotions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gs/hs1/tga-i/otake.s.ad/SER/torchemotion/datasets/IemocapDataset.py:58: FutureWarning: Could not cast to float32, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  self.df = pd.DataFrame(data, columns=['start', 'end', 'file', 'emotion', 'activation', 'valence', 'dominance', 'session', 'script_impro', 'gender', 'utterance'], dtype=np.float32)\n"
     ]
    }
   ],
   "source": [
    "labels = ['ang', 'hap', 'sad', 'neu']\n",
    "Iemocap = IemocapDataset(root='./data/IEMOCAP_full_release', emotions=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './data/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_script02_2/Ses01M_script02_2_F000.wav',\n",
       " 'waveform': tensor([[-0.0034, -0.0037, -0.0033,  ..., -0.0053, -0.0050, -0.0036]]),\n",
       " 'sample_rate': 16000,\n",
       " 'emotion': 7.0,\n",
       " 'activation': 4.0,\n",
       " 'valence': 2.0,\n",
       " 'dominance': 2.5}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = torch.tensor(lengths)\n",
    "subset = [Iemocap[i] for i, v in enumerate((lengths<250000).tolist()) if v]\n",
    "subset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5477"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "eiQmRq2qaZ75",
    "outputId": "e6edeed9-ab5d-41e7-d785-77c7671c5232"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset stratified by emotion\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "emotions = [int(emodb.__getitem__(i)['emotion'])-1 for i in range(len(emodb))]\n",
    "train_indices, val_indices = train_test_split(list(range(len(emotions))), test_size=0.2, stratify=emotions, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(emodb, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(emodb, val_indices)\n",
    "\n",
    "emotions_train = [int(train_dataset.__getitem__(i)['emotion'])-1 for i in range(len(train_dataset))]\n",
    "plt.hist(emotions, label='all')\n",
    "plt.hist(emotions_train, label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "eiQmRq2qaZ75",
    "outputId": "e6edeed9-ab5d-41e7-d785-77c7671c5232"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset stratified by emotion\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = subset\n",
    "\n",
    "emotions = [int(dataset[i]['emotion']) for i in range(len(dataset))]\n",
    "\n",
    "train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, stratify=emotions, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "emotions_train = [int(train_dataset.__getitem__(i)['emotion']) for i in range(len(train_dataset))]\n",
    "plt.hist(emotions, label='all')\n",
    "plt.hist(emotions_train, label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1041., 1735., 1033.,  637.,  405.,  259.,  146.,  105.,   58.,\n",
       "          58.]),\n",
       " array([  9359.,  33351.,  57343.,  81335., 105327., 129319., 153311.,\n",
       "        177303., 201295., 225287., 249279.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [subset[i]['waveform'].size(-1) for i in range(len(subset))]\n",
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxoRdsmvh---",
    "outputId": "c01bd1a1-be0b-401c-d94c-5bfdd1c17bec"
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\") # 前処理\n",
    "#wavlm = WavLMModel.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\") # wavlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at patrickvonplaten/wavlm-libri-clean-100h-base-plus were not used when initializing WavLMForSequenceClassification: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing WavLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMForSequenceClassification were not initialized from the model checkpoint at patrickvonplaten/wavlm-libri-clean-100h-base-plus and are newly initialized: ['classifier.weight', 'projector.bias', 'projector.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "wavlmcl = WavLMForSequenceClassification.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgcEgxbyzrQ2"
   },
   "outputs": [],
   "source": [
    "# collate_fn\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\") # 前処理\n",
    "\n",
    "def pad_sequence(batch):\n",
    "    # ゼロ埋めによりバッチに含まれる全てのテンソルを同じ長さにする\n",
    "\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    #print(batch.shape)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "\n",
    "    waveforms, targets = [], []\n",
    "    input_data = {}\n",
    "\n",
    "    # リストにまとめ、ラベルをインデックスでエンコードする\n",
    "    for data in batch:\n",
    "        waveforms += [data['waveform']]\n",
    "        targets += [torch.tensor(int(data['emotion'])-1)]\n",
    "\n",
    "    # テンソルのリストをまとめてバッチ化されたテンソルにする\n",
    "    waveforms = pad_sequence(waveforms)\n",
    "    waveforms = [torch.flatten(w) for w in waveforms]\n",
    "    inputs = [processor(waveform, sampling_rate=16000, return_tensors='pt', padding=True) for waveform in waveforms]\n",
    "    input_data['input_values'] = torch.stack([inputs[i]['input_values'].flatten() for i in range(len(batch))])\n",
    "    input_data['attention_mask'] = torch.stack([inputs[i]['attention_mask'].flatten() for i in range(len(batch))])\n",
    "\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return input_data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c2EugY6Sjc3W"
   },
   "outputs": [],
   "source": [
    "# collate_fn\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\") \n",
    "# emodb\n",
    "def collate_fn(batch):\n",
    "    waveforms, targets = [], []\n",
    "    input_data = {}\n",
    "\n",
    "    # リストにまとめ、ラベルをインデックスでエンコードする\n",
    "    for data in batch:\n",
    "        waveforms += [data['waveform'].numpy().flatten()]\n",
    "        targets += [torch.tensor(int(data['emotion'])-1)]\n",
    "\n",
    "    # テンソルのリストをまとめてバッチ化されたテンソルにする\n",
    "    '''waveforms = pad_sequence(waveforms)\n",
    "    waveforms = torch.stack([torch.flatten(w) for w in waveforms])\n",
    "'''\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return waveforms, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate_fn\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\") \n",
    "# IEMOCAP\n",
    "def collate_fn(batch):\n",
    "    waveforms, targets = [], []\n",
    "    input_data = {}\n",
    "\n",
    "    # リストにまとめ、ラベルをインデックスでエンコードする\n",
    "    for data in batch:\n",
    "        waveforms += [data['waveform'].numpy().flatten()]\n",
    "        emotion = data['emotion']\n",
    "        targets += [torch.tensor(int(data['emotion']))]\n",
    "\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return waveforms, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ryO7sWVxs_Ha"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ZiADeH8UKOle"
   },
   "outputs": [],
   "source": [
    "data,target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 3.6621094e-04,  1.8310547e-04, -9.1552734e-05, ...,\n",
       "        -1.1596680e-03, -8.2397461e-04, -3.9672852e-04], dtype=float32),\n",
       " array([-0.01104736, -0.01046753, -0.00863647, ..., -0.0043335 ,\n",
       "        -0.00476074, -0.00500488], dtype=float32),\n",
       " array([-0.0090332 , -0.01098633, -0.01187134, ..., -0.00201416,\n",
       "        -0.00204468, -0.00198364], dtype=float32),\n",
       " array([-0.0010376 , -0.00106812, -0.00189209, ..., -0.0045166 ,\n",
       "        -0.00457764, -0.00466919], dtype=float32),\n",
       " array([-0.00305176, -0.00271606, -0.00256348, ...,  0.00299072,\n",
       "         0.00299072,  0.0027771 ], dtype=float32),\n",
       " array([-0.00073242, -0.0010376 , -0.00131226, ..., -0.00030518,\n",
       "        -0.00042725, -0.00061035], dtype=float32),\n",
       " array([ 0.00247192,  0.00219727,  0.00183105, ...,  0.00210571,\n",
       "        -0.00653076, -0.01220703], dtype=float32),\n",
       " array([ 0.00802612,  0.00726318,  0.00668335, ..., -0.00076294,\n",
       "        -0.00033569, -0.00012207], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 3., 3., 3., 0., 1.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavlm_config = WavLMConfig('patrickvonplaten/wavlm-libri-clean-100h-base-plus')\n",
    "wavlm_config.update({'num_labels':7, 'use_weighted_layer_sum':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavlm_config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at patrickvonplaten/wavlm-libri-clean-100h-base-plus were not used when initializing WavLMForSequenceClassification: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing WavLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMForSequenceClassification were not initialized from the model checkpoint at patrickvonplaten/wavlm-libri-clean-100h-base-plus and are newly initialized: ['layer_weights', 'classifier.weight', 'projector.bias', 'projector.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\") # 前処理\n",
    "model = WavLMForSequenceClassification.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\", config=wavlm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_weighted_layer_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(data, sampling_rate=16000, returns_tensor='pt', padding=True)\n",
    "output = model(**input, labels=target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "DRDOY8xGRGvB",
    "outputId": "033c618b-e0fe-4e56-97e9-203bb67ba55f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n\\nmodel = SERwithWavLM(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\")\\n#model = nn.DataParallel(model, list(range(4)))\\nmodel.to(device)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの定義\n",
    "class SERwithWavLM(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.processor =  Wav2Vec2Processor.from_pretrained(pretrained_model)\n",
    "        self.wavlm = WavLMModel.from_pretrained(pretrained_model)\n",
    "        self.fc = nn.Linear(768, 7)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = self.processor(input, sampling_rate=16000,  return_tensors='pt', padding=True)\n",
    "        for k in input.keys():\n",
    "            input[k] = input[k].to(device)\n",
    "        wavlm_output = self.wavlm(**input).last_hidden_state\n",
    "        output = self.fc(wavlm_output.mean(dim=1))\n",
    "        return output, wavlm_output\n",
    "\n",
    "\n",
    "'''device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SERwithWavLM(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\")\n",
    "#model = nn.DataParallel(model, list(range(4)))\n",
    "model.to(device)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SERwithWavLM(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\")\n",
    "model = nn.DataParallel(model, list(range(4)))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-38ac0dc38226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'fc'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'fc' in name:\n",
    "        print(name)\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uct0URSS_BcR",
    "outputId": "595b305c-1e11-41a7-ceb9-4c451884c52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 5383\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rppqxc5Y0Oy8",
    "outputId": "ba7efd7f-3c05-411e-f833-99b8a1bd55a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model動作確認\n",
    "data, target = next(iter(train_loader))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, hidden_state = model(data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zj18CUqG8KZ0",
    "outputId": "6137b110-0f56-48de-c578-8995ab1fd015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 3, 2, 6, 4, 6, 1])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(target)\n",
    "print(output.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53C5xz2tI4P0",
    "outputId": "fbcf85d8-4d25-4f1d-ccb6-919dfdbfa340"
   },
   "outputs": [],
   "source": [
    "print(hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjyittnfHAL7",
    "outputId": "fba89eac-1a8f-4e75-e009-2b5971bc09b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0037,  0.0032,  0.0257,  ..., -0.0358,  0.0293,  0.0250],\n",
       "         [ 0.0314,  0.0140,  0.0354,  ...,  0.0177, -0.0351,  0.0253],\n",
       "         [-0.0082, -0.0273, -0.0351,  ..., -0.0185,  0.0148, -0.0161],\n",
       "         ...,\n",
       "         [-0.0315, -0.0312, -0.0334,  ...,  0.0277,  0.0352,  0.0122],\n",
       "         [-0.0125,  0.0157, -0.0210,  ...,  0.0099,  0.0216,  0.0143],\n",
       "         [ 0.0026, -0.0029, -0.0121,  ...,  0.0315,  0.0253,  0.0318]],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0194, -0.0339, -0.0003, -0.0106, -0.0273,  0.0057,  0.0162],\n",
       "        device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiwzTrnFn8FC"
   },
   "source": [
    "以降は\n",
    "[speech_command tutorial](https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html)の流用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oGuTbX3xL9kx"
   },
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # 正解数を数える\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # バッチの各要素について、最も確率の高いラベルインデックスを得る\n",
    "    return tensor.argmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tRu9U6WEBXdV"
   },
   "outputs": [],
   "source": [
    "# 最適化 \n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=lr, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ih8xU3APc-69",
    "outputId": "acd3d9a2-fd72-4b28-eb8c-b37e63d570e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshinos\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HovaDhPUhO5V"
   },
   "source": [
    "wandb example\n",
    "```python\n",
    "# Launch 5 experiments, trying different dropout rates\n",
    "for _ in range(5):\n",
    "    # 🐝 initialise a wandb run\n",
    "    wandb.init(\n",
    "        project=\"pytorch-intro\",\n",
    "        config={\n",
    "            \"epochs\": 10,\n",
    "            \"batch_size\": 128,\n",
    "            \"lr\": 1e-3,\n",
    "            \"dropout\": random.uniform(0.01, 0.80),\n",
    "            })\n",
    "    \n",
    "    # Copy your config \n",
    "    config = wandb.config\n",
    "\n",
    "    # Get the data\n",
    "    train_dl = get_dataloader(is_train=True, batch_size=config.batch_size)\n",
    "    valid_dl = get_dataloader(is_train=False, batch_size=2*config.batch_size)\n",
    "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "    \n",
    "    # A simple MLP model\n",
    "    model = get_model(config.dropout)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "   # Training\n",
    "    example_ct = 0\n",
    "    step_ct = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        model.train()\n",
    "        for step, (images, labels) in enumerate(tqdm(train_dl, leave=False)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            example_ct += len(images)\n",
    "            metrics = {\"train/train_loss\": train_loss, \n",
    "                       \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch, \n",
    "                       \"train/example_ct\": example_ct}\n",
    "            \n",
    "            if step + 1 < n_steps_per_epoch:\n",
    "                # 🐝 Log train metrics to wandb \n",
    "                wandb.log(metrics)\n",
    "                \n",
    "            step_ct += 1\n",
    "\n",
    "        val_loss, accuracy = validate_model(model, valid_dl, loss_func, log_images=(epoch==(config.epochs-1)))\n",
    "\n",
    "        # 🐝 Log train and validation metrics to wandb\n",
    "        val_metrics = {\"val/val_loss\": val_loss, \n",
    "                       \"val/val_accuracy\": accuracy}\n",
    "        wandb.log({**metrics, **val_metrics})\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # If you had a test set, this is how you could log it as a Summary metric\n",
    "    wandb.summary['test_accuracy'] = 0.8\n",
    "\n",
    "    # 🐝 Close your wandb run \n",
    "    wandb.finish()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QJkL_xA7e4-"
   },
   "source": [
    "```python\n",
    "def number_of_correct(pred, target):\n",
    "    # 正解数を数える\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # バッチの各要素について、最も確率の高いラベルインデックスを得る\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "# train\n",
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "\n",
    "    for step, (data, target) in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # モデルへ入力する\n",
    "        output,_ = model(data)\n",
    "\n",
    "        # クロスエントロピー誤差\n",
    "        loss = F.cross_entropy(output, target, ignore_index=0)\n",
    "        \n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metrics = {\"train/loss\": loss.item()/len(data)}\n",
    "        #if step + 1 < n_steps_per_epoch:\n",
    "        wandb.log(metrics)\n",
    "        #print(list(model.parameters())[0][0])\n",
    "        # 訓練の統計値をプリントする\n",
    "        if step % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{step * len(target)}/{len(train_loader.dataset)} ({100. * step / len(train_loader):.0f}%)]\\tLoss: {loss.item()/len(data):.6f}\")\n",
    "\n",
    "        # プログレスバー更新\n",
    "        pbar.update(pbar_update)\n",
    "        # 損失を記録する\n",
    "        losses.append(loss.item()/len(data))\n",
    "    print(f\"Accuracy: {correct}/{len(train_loader.dataset)} ({100. * correct / len(train_loader.dataset):.0f}%)\")\n",
    "    metrics = {'train/epoch_loss': sum(losses)/len(losses)}\n",
    "    return metrics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hb6jscV7e4_"
   },
   "source": [
    "```python\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    example_ct = 0\n",
    "    val_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        example_ct += len(data)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # モデルへ入力する\n",
    "        output,_ = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        val_loss += F.cross_entropy(output, target, ignore_index=0)\n",
    "\n",
    "        print(pred)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "        \n",
    "        # プログレスバー更新\n",
    "        pbar.update(pbar_update)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    val_metrics = {\"val/val_loss\": val_loss/example_ct, \n",
    "              \"val/val_accuracy\": accuracy}\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n\")\n",
    "    \n",
    "    return val_metrics\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712,
     "referenced_widgets": [
      "9c25575c795c498dad30ddb60a54992f",
      "d2aad960f4e147c39bbf4e3486ae8abf",
      "7a2585dcff9e46d2b3e429cdfe15251b",
      "344d4d40846c48c5b23d1f2f004a6a2c",
      "16931946ca934132bc47219683486303",
      "96817ccf7f694652a9ee52704bc833df",
      "c2843e7055024ca59738182107150ae3",
      "10bc24d58dd64baf9875951175d53cb7",
      "13593a06989240bd8d2cca1d13d302c7",
      "f605ea8772394995828669527c9e39c7",
      "deb1de98e25f4fb798c9d721e4dcca04"
     ]
    },
    "id": "YLLMfDvu7e4_",
    "outputId": "a628eaa7-f6dc-4b61-e971-1274c29c323a"
   },
   "source": [
    "```python\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "wandb.init(\n",
    "    project=\"wavlm_SER_IEMOCAP\",\n",
    "    config={\n",
    "        \"pretrained_model\": 'patrickvonplaten/wavlm-libri-clean-100h-base-plus',\n",
    "        \"epochs\": 20,\n",
    "        \"batch_size\": 8,\n",
    "        \"learning_rate\": 0.0005, \n",
    "        \"lr_scheduler_step\": 20,\n",
    "        \"lr_scheduler_gamma\": 0.5\n",
    "        })\n",
    "config = wandb.config\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = SERwithWavLM(config[\"pretrained_model\"])\n",
    "model = nn.DataParallel(model, list(range(4)))\n",
    "model.to(device)\n",
    "\n",
    "param_to_update = []\n",
    "param_to_update_name = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'fc' in name:\n",
    "        print(name)\n",
    "        param.requires_grad = True\n",
    "        param_to_update.append(param)\n",
    "        param_to_update_name.append(name)\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "wandb.config.update({\"updated_param_name\": param_to_update_name})\n",
    "optimizer = torch.optim.Adam(param_to_update, lr=config['learning_rate'], weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"lr_scheduler_step\"], gamma=config[\"lr_scheduler_gamma\"]) \n",
    "\n",
    "log_interval = 10\n",
    "n_epoch = config[\"epochs\"]\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        metrics = train(model, epoch, log_interval)\n",
    "        val_metrics = test(model, epoch)\n",
    "        scheduler.step()\n",
    "        wandb.log({**metrics, **val_metrics})\n",
    "\n",
    "# 訓練時の損失がイテレーション数に応じてどう変化するかをプロットする\n",
    "# plt.plot(losses);\n",
    "# plt.title(\"training loss\");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for v in dataloaders_dict.values():\n",
    "    print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(v) for v in dataloaders_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6, 4, 2, 5, 1, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1894"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / sum([len(v) for v in dataloaders_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders_dict, optimizer, scheduler, num_epochs, log_interval=10):\n",
    "\n",
    "    '''# GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    model.to(device)'''\n",
    "    \n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    log_intervals = 10\n",
    "    pbar_update = 1 / sum([len(v) for v in dataloaders_dict.values()])\n",
    "    \n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wavlm-libri-clean-100h-base-plus\")\n",
    "    with tqdm(total=num_epochs) as pbar:\n",
    "        # epochのループ\n",
    "        for epoch in range(num_epochs):\n",
    "            # epochごとの訓練と検証のループ\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # モデルを訓練モードに\n",
    "                else:\n",
    "                    model.eval()   # モデルを検証モードに\n",
    "\n",
    "                epoch_loss = 0.0  # epochの損失和\n",
    "                epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "                # データローダーからミニバッチを取り出すループ\n",
    "                for step, (data, target) in enumerate(dataloaders_dict[phase]):\n",
    "                    # GPUが使えるならGPUにデータを送る\n",
    "                    inputs = processor(data, sampling_rate=16000,  return_tensors='pt', padding=True)\n",
    "                    for k in inputs.keys():\n",
    "                        inputs[k] = inputs[k].to(device)\n",
    "                    target = target.to(device)\n",
    "                    inputs = (inputs, target)\n",
    "                    \n",
    "                    # optimizerを初期化\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # 順伝搬（forward）計算\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                        # modelに入力\n",
    "                        # outputs, _ = model(inputs, target)\n",
    "                        # loss = F.nll_loss(F.log_softmax(outputs, dim=-1), target)  # 損失を計算 reduction='mean'\n",
    "                        logits, loss = model(inputs)\n",
    "                        preds = torch.argmax(logits, dim=-1)  # ラベルを予測\n",
    "\n",
    "                        # 訓練時はバックプロパゲーション\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            if scheduler is not None:\n",
    "                                scheduler.step()\n",
    "                            loss_log = loss.item()\n",
    "                            del loss\n",
    "                            if step % log_interval == 0:\n",
    "                                print(f\"Train Epoch: {epoch} [{step * len(data)}/{len(dataloaders_dict[phase].dataset)} ({100. * step / len(dataloaders_dict[phase]):.0f}%)]\\tLoss: {loss_log:.6f}\")\n",
    "                            wandb.log({'train/loss': loss_log})\n",
    "                            \n",
    "                        else:\n",
    "                            print(preds.to('cpu').detach().numpy())\n",
    "                        # 結果の計算\n",
    "                        epoch_loss += loss_log * len(data)\n",
    "                        # 正解数の合計を更新\n",
    "                        epoch_corrects += preds.squeeze().eq(target).sum().item()\n",
    "                \n",
    "                '''if phase=='train':\n",
    "                    before = scheduler.get_lr()[0]\n",
    "                    scheduler.step()\n",
    "                    after = scheduler.get_lr()[0]\n",
    "                    print(f'\\nsceduler\\n {before} -> {after}')'''\n",
    "                    \n",
    "                # epochごとのlossと正解率\n",
    "                epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "                epoch_acc = epoch_corrects / len(dataloaders_dict[phase].dataset)\n",
    "               \n",
    "                metrics = {f'{phase}/epoch_loss': epoch_loss, f'{phase}/acc': epoch_acc}\n",
    "                wandb.log(metrics)\n",
    "                \n",
    "                pbar.update(pbar_update)\n",
    "                print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                               phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QOqOBe_AoQkK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1lj1yblh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">colorful-vortex-79</strong>: <a href=\"https://wandb.ai/shinos/wavlm_SER/runs/1lj1yblh\" target=\"_blank\">https://wandb.ai/shinos/wavlm_SER/runs/1lj1yblh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220413_094732-1lj1yblh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1lj1yblh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/gs/hs1/tga-i/otake.s.ad/SER/wandb/run-20220413_094839-28s1ec2t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/shinos/wavlm_SER/runs/28s1ec2t\" target=\"_blank\">resilient-sponge-80</a></strong> to <a href=\"https://wandb.ai/shinos/wavlm_SER\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at patrickvonplaten/wavlm-libri-clean-100h-base-plus were not used when initializing WavLMForSequenceClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing WavLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMForSequenceClassification were not initialized from the model checkpoint at patrickvonplaten/wavlm-libri-clean-100h-base-plus and are newly initialized: ['projector.weight', 'classifier.bias', 'classifier.weight', 'projector.bias', 'layer_weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e73260f09224ca38fa4e3bdb463e854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1497 (0%)]\tLoss: 1.420434\n",
      "Train Epoch: 0 [80/1497 (5%)]\tLoss: 1.219347\n",
      "Train Epoch: 0 [160/1497 (11%)]\tLoss: 1.409039\n",
      "Train Epoch: 0 [240/1497 (16%)]\tLoss: 1.245827\n",
      "Train Epoch: 0 [320/1497 (21%)]\tLoss: 1.375381\n",
      "Train Epoch: 0 [400/1497 (27%)]\tLoss: 1.241039\n",
      "Train Epoch: 0 [480/1497 (32%)]\tLoss: 1.287493\n",
      "Train Epoch: 0 [560/1497 (37%)]\tLoss: 1.272001\n",
      "Train Epoch: 0 [640/1497 (43%)]\tLoss: 1.093808\n",
      "Train Epoch: 0 [720/1497 (48%)]\tLoss: 0.921091\n",
      "Train Epoch: 0 [800/1497 (53%)]\tLoss: 1.511650\n",
      "Train Epoch: 0 [880/1497 (59%)]\tLoss: 1.102845\n",
      "Train Epoch: 0 [960/1497 (64%)]\tLoss: 0.996432\n",
      "Train Epoch: 0 [1040/1497 (69%)]\tLoss: 1.128203\n",
      "Train Epoch: 0 [1120/1497 (74%)]\tLoss: 0.921378\n",
      "Train Epoch: 0 [1200/1497 (80%)]\tLoss: 1.158976\n",
      "Train Epoch: 0 [1280/1497 (85%)]\tLoss: 1.138573\n",
      "Train Epoch: 0 [1360/1497 (90%)]\tLoss: 1.215854\n",
      "Train Epoch: 0 [1440/1497 (96%)]\tLoss: 0.743695\n",
      "Epoch 1/10 | train |  Loss: 1.1594 Acc: 0.4950\n",
      "[2 0 2 2 1 2 1 0]\n",
      "[0 2 1 3 0 2 2 2]\n",
      "[2 2 2 1 1 1 0 0]\n",
      "[3 2 2 2 0 2 0 2]\n",
      "[2 0 3 2 2 1 2 0]\n",
      "[2 0 0 2 2 0 2 2]\n",
      "[2 2 2 2 0 2 0 2]\n",
      "[0 2 2 2 1 2 0 1]\n",
      "[2 2 3 3 2 3 1 3]\n",
      "[2 3 1 0 2 2 3 0]\n",
      "[2 0 3 2 3 2 2 2]\n",
      "[2 0 0 1 2 0 2 2]\n",
      "[0 0 3 0 0 0 2 2]\n",
      "[2 0 2 1 3 0 0 3]\n",
      "[3 0 3 2 3 0 0 2]\n",
      "[2 2 2 0 2 3 2 2]\n",
      "[2 0 2 2 2 0 2 0]\n",
      "[1 2 2 2 3 2 1 0]\n",
      "[3 3 0 1 0 1 3 0]\n",
      "[0 2 0 2 2 2 2 2]\n",
      "[2 2 0 0 2 0 2 2]\n",
      "[2 0 2 2 3 2 0 2]\n",
      "[2 2 0 3 2 0 1 2]\n",
      "[2 3 0 2 2 3 2 3]\n",
      "[3 3 0 1 2 2 2 0]\n",
      "[2 1 0 2 1 2 2 2]\n",
      "[1 2 2 0 2 0 2 2]\n",
      "[3 2 3 3 2 1 2 2]\n",
      "[0 0 2 2 0 1 0 2]\n",
      "[2 2 2 2 1 0 0 2]\n",
      "[2 2 2 2 0 3 2 2]\n",
      "[2 0 0 0 2 1 0 0]\n",
      "[2 3 2 2 2 3 2 2]\n",
      "[2 0 0 0 0 0 3 0]\n",
      "[0 2 0 2 2 0 2 0]\n",
      "[0 1 2 2 2 2 0 3]\n",
      "[2 0 2 2 2 2 0 3]\n",
      "[2 3 2 0 0 3 2 2]\n",
      "[3 2 3 2 2 2 1 2]\n",
      "[2 2 2 0 2 2 2 3]\n",
      "[2 2 1 2 1 2 0 0]\n",
      "[0 0 0 3 2 3 0 2]\n",
      "[3 0 3 3 2 2 1 0]\n",
      "[0 0 2 2 0 0 2 1]\n",
      "[0 2 2 2 2 2 2 3]\n",
      "[2 1 1 3 0 2 2 2]\n",
      "[0 1 3 1 1 0 3]\n",
      "Epoch 1/10 |  val  |  Loss: 1.3914 Acc: 0.5360\n",
      "Train Epoch: 1 [0/1497 (0%)]\tLoss: 1.012522\n",
      "Train Epoch: 1 [80/1497 (5%)]\tLoss: 1.528530\n",
      "Train Epoch: 1 [160/1497 (11%)]\tLoss: 0.776151\n",
      "Train Epoch: 1 [240/1497 (16%)]\tLoss: 0.776156\n",
      "Train Epoch: 1 [320/1497 (21%)]\tLoss: 0.505316\n",
      "Train Epoch: 1 [400/1497 (27%)]\tLoss: 1.215462\n",
      "Train Epoch: 1 [480/1497 (32%)]\tLoss: 0.742416\n",
      "Train Epoch: 1 [560/1497 (37%)]\tLoss: 0.985781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/1497 (43%)]\tLoss: 1.304337\n",
      "Train Epoch: 1 [720/1497 (48%)]\tLoss: 0.987195\n",
      "Train Epoch: 1 [800/1497 (53%)]\tLoss: 0.618266\n",
      "Train Epoch: 1 [880/1497 (59%)]\tLoss: 1.323364\n",
      "Train Epoch: 1 [960/1497 (64%)]\tLoss: 0.728942\n",
      "Train Epoch: 1 [1040/1497 (69%)]\tLoss: 1.092866\n",
      "Train Epoch: 1 [1120/1497 (74%)]\tLoss: 1.460201\n",
      "Train Epoch: 1 [1200/1497 (80%)]\tLoss: 0.712858\n",
      "Train Epoch: 1 [1280/1497 (85%)]\tLoss: 0.879399\n",
      "Train Epoch: 1 [1360/1497 (90%)]\tLoss: 0.717871\n",
      "Train Epoch: 1 [1440/1497 (96%)]\tLoss: 0.995831\n",
      "Epoch 2/10 | train |  Loss: 0.9958 Acc: 0.5912\n",
      "[2 0 2 3 1 2 0 0]\n",
      "[3 2 0 2 0 2 2 2]\n",
      "[2 2 2 3 1 1 0 0]\n",
      "[3 2 2 1 0 2 0 2]\n",
      "[2 0 3 2 2 1 2 0]\n",
      "[2 0 0 2 2 0 2 2]\n",
      "[2 2 2 2 1 2 0 2]\n",
      "[0 2 2 3 1 2 0 1]\n",
      "[2 2 3 3 1 1 1 2]\n",
      "[2 2 1 0 0 2 3 0]\n",
      "[2 1 2 2 3 2 2 2]\n",
      "[2 1 1 1 2 0 2 2]\n",
      "[0 0 3 0 1 1 2 2]\n",
      "[2 1 2 1 3 1 0 2]\n",
      "[3 0 1 1 2 0 0 2]\n",
      "[2 2 2 0 2 3 2 2]\n",
      "[2 0 3 2 2 0 2 0]\n",
      "[1 2 2 2 3 2 0 0]\n",
      "[3 3 0 0 0 0 3 0]\n",
      "[0 2 1 2 2 2 2 2]\n",
      "[2 1 0 0 2 0 2 2]\n",
      "[2 0 2 2 3 2 0 3]\n",
      "[2 2 0 3 0 0 0 2]\n",
      "[3 3 0 2 2 3 2 1]\n",
      "[3 1 1 0 2 2 2 0]\n",
      "[2 1 0 2 1 2 2 2]\n",
      "[1 2 1 1 2 0 2 2]\n",
      "[3 2 3 2 2 0 2 2]\n",
      "[0 0 3 2 0 1 0 2]\n",
      "[2 2 2 2 1 0 0 2]\n",
      "[3 2 2 2 0 2 2 2]\n",
      "[3 0 0 3 2 1 0 1]\n",
      "[2 0 2 2 2 3 2 2]\n",
      "[2 0 0 0 0 0 3 0]\n",
      "[0 2 0 2 2 0 2 0]\n",
      "[0 1 2 2 2 1 0 3]\n",
      "[2 0 2 2 2 2 0 3]\n",
      "[3 3 2 1 1 3 2 2]\n",
      "[0 2 3 2 2 2 1 2]\n",
      "[2 2 0 1 2 2 2 3]\n",
      "[2 2 1 2 1 2 0 0]\n",
      "[0 0 0 1 2 3 1 2]\n",
      "[2 0 0 3 2 2 1 0]\n",
      "[1 0 1 2 0 3 0 1]\n",
      "[0 2 2 1 2 2 2 3]\n",
      "[2 1 1 3 0 2 1 2]\n",
      "[0 0 3 1 1 0 1]\n",
      "Epoch 2/10 |  val  |  Loss: 0.0665 Acc: 0.5973\n",
      "Train Epoch: 2 [0/1497 (0%)]\tLoss: 0.369731\n",
      "Train Epoch: 2 [80/1497 (5%)]\tLoss: 1.220188\n",
      "Train Epoch: 2 [160/1497 (11%)]\tLoss: 0.618777\n",
      "Train Epoch: 2 [240/1497 (16%)]\tLoss: 0.948077\n",
      "Train Epoch: 2 [320/1497 (21%)]\tLoss: 0.733813\n",
      "Train Epoch: 2 [400/1497 (27%)]\tLoss: 0.817890\n",
      "Train Epoch: 2 [480/1497 (32%)]\tLoss: 0.892934\n",
      "Train Epoch: 2 [560/1497 (37%)]\tLoss: 0.904836\n",
      "Train Epoch: 2 [640/1497 (43%)]\tLoss: 0.854010\n",
      "Train Epoch: 2 [720/1497 (48%)]\tLoss: 0.877479\n",
      "Train Epoch: 2 [800/1497 (53%)]\tLoss: 1.181994\n",
      "Train Epoch: 2 [880/1497 (59%)]\tLoss: 1.058803\n",
      "Train Epoch: 2 [960/1497 (64%)]\tLoss: 1.322993\n",
      "Train Epoch: 2 [1040/1497 (69%)]\tLoss: 0.842050\n",
      "Train Epoch: 2 [1120/1497 (74%)]\tLoss: 0.631258\n",
      "Train Epoch: 2 [1200/1497 (80%)]\tLoss: 1.087996\n",
      "Train Epoch: 2 [1280/1497 (85%)]\tLoss: 0.429921\n",
      "Train Epoch: 2 [1360/1497 (90%)]\tLoss: 1.071854\n",
      "Train Epoch: 2 [1440/1497 (96%)]\tLoss: 0.802184\n",
      "Epoch 3/10 | train |  Loss: 0.8864 Acc: 0.6266\n",
      "[2 1 2 3 0 2 0 0]\n",
      "[3 1 1 3 0 2 2 2]\n",
      "[2 2 2 3 1 1 0 0]\n",
      "[3 2 2 1 0 3 0 0]\n",
      "[2 0 3 2 2 1 1 0]\n",
      "[2 0 0 3 3 0 1 2]\n",
      "[2 2 2 2 1 1 1 2]\n",
      "[0 2 2 3 3 2 0 1]\n",
      "[3 2 3 3 0 1 1 3]\n",
      "[2 3 1 0 0 1 3 0]\n",
      "[2 0 3 1 3 2 2 1]\n",
      "[2 1 3 1 1 0 1 2]\n",
      "[0 0 0 0 1 1 2 2]\n",
      "[2 0 2 0 3 1 0 1]\n",
      "[3 0 3 1 3 0 0 3]\n",
      "[2 2 2 0 2 3 3 3]\n",
      "[2 0 3 3 2 0 1 0]\n",
      "[1 2 2 1 3 2 0 0]\n",
      "[3 3 0 0 0 1 3 0]\n",
      "[0 2 0 2 2 2 2 3]\n",
      "[2 0 0 0 3 0 2 2]\n",
      "[1 0 2 2 3 2 0 3]\n",
      "[2 2 0 3 0 0 0 2]\n",
      "[3 3 0 3 2 1 2 1]\n",
      "[3 1 1 0 2 2 2 0]\n",
      "[3 1 0 2 1 2 2 2]\n",
      "[0 2 1 1 2 0 2 1]\n",
      "[3 2 0 3 1 0 3 2]\n",
      "[0 0 3 3 0 1 0 2]\n",
      "[2 3 2 2 1 0 0 3]\n",
      "[3 3 3 1 0 3 2 2]\n",
      "[3 0 0 3 2 1 3 0]\n",
      "[2 1 2 2 2 1 2 2]\n",
      "[2 0 0 0 0 0 1 1]\n",
      "[0 2 1 3 2 0 3 0]\n",
      "[1 0 2 1 1 1 0 3]\n",
      "[3 0 1 2 1 2 0 3]\n",
      "[3 3 2 1 3 3 2 2]\n",
      "[1 3 0 2 2 2 0 2]\n",
      "[2 2 0 1 2 3 1 3]\n",
      "[2 1 1 2 1 3 0 0]\n",
      "[0 0 0 1 2 3 1 2]\n",
      "[1 0 0 3 2 2 2 0]\n",
      "[1 0 0 1 0 3 0 3]\n",
      "[0 2 2 1 3 2 1 3]\n",
      "[2 0 0 3 0 1 1 1]\n",
      "[0 0 3 1 1 0 1]\n",
      "Epoch 3/10 |  val  |  Loss: 2.2232 Acc: 0.6667\n",
      "Train Epoch: 3 [0/1497 (0%)]\tLoss: 0.999191\n",
      "Train Epoch: 3 [80/1497 (5%)]\tLoss: 1.000013\n",
      "Train Epoch: 3 [160/1497 (11%)]\tLoss: 0.754175\n",
      "Train Epoch: 3 [240/1497 (16%)]\tLoss: 0.672535\n",
      "Train Epoch: 3 [320/1497 (21%)]\tLoss: 0.378176\n",
      "Train Epoch: 3 [400/1497 (27%)]\tLoss: 0.518711\n",
      "Train Epoch: 3 [480/1497 (32%)]\tLoss: 0.809208\n",
      "Train Epoch: 3 [560/1497 (37%)]\tLoss: 1.242533\n",
      "Train Epoch: 3 [640/1497 (43%)]\tLoss: 0.610085\n",
      "Train Epoch: 3 [720/1497 (48%)]\tLoss: 0.932936\n",
      "Train Epoch: 3 [800/1497 (53%)]\tLoss: 0.654032\n",
      "Train Epoch: 3 [880/1497 (59%)]\tLoss: 0.692508\n",
      "Train Epoch: 3 [960/1497 (64%)]\tLoss: 0.795589\n",
      "Train Epoch: 3 [1040/1497 (69%)]\tLoss: 0.564721\n",
      "Train Epoch: 3 [1120/1497 (74%)]\tLoss: 0.501395\n",
      "Train Epoch: 3 [1200/1497 (80%)]\tLoss: 0.880657\n",
      "Train Epoch: 3 [1280/1497 (85%)]\tLoss: 1.263772\n",
      "Train Epoch: 3 [1360/1497 (90%)]\tLoss: 0.604286\n",
      "Train Epoch: 3 [1440/1497 (96%)]\tLoss: 0.401276\n",
      "Epoch 4/10 | train |  Loss: 0.7966 Acc: 0.6900\n",
      "[2 1 2 3 1 2 0 0]\n",
      "[3 3 1 3 0 2 2 2]\n",
      "[2 2 2 3 1 1 1 1]\n",
      "[3 2 2 1 0 3 1 2]\n",
      "[2 0 3 2 2 1 1 0]\n",
      "[2 0 0 2 3 0 2 2]\n",
      "[2 2 2 2 1 2 1 2]\n",
      "[0 2 2 3 1 2 0 1]\n",
      "[3 2 3 1 1 1 1 3]\n",
      "[2 3 1 0 1 2 1 1]\n",
      "[2 1 3 2 3 2 2 1]\n",
      "[2 1 1 1 1 1 2 2]\n",
      "[1 0 3 0 1 1 2 2]\n",
      "[2 1 2 1 3 1 1 1]\n",
      "[3 0 3 1 3 0 0 3]\n",
      "[2 2 2 0 2 3 3 3]\n",
      "[2 0 3 3 2 0 2 1]\n",
      "[1 2 2 2 3 2 1 0]\n",
      "[3 3 0 1 0 1 3 0]\n",
      "[0 2 1 2 2 2 2 3]\n",
      "[2 1 1 1 3 0 2 1]\n",
      "[3 0 2 2 3 2 0 3]\n",
      "[2 2 1 3 1 0 1 2]\n",
      "[3 3 1 3 2 1 2 1]\n",
      "[3 1 1 1 3 2 2 0]\n",
      "[3 1 0 2 1 2 2 2]\n",
      "[1 2 1 1 2 1 3 3]\n",
      "[3 2 1 1 2 1 2 2]\n",
      "[0 0 3 3 0 1 0 2]\n",
      "[2 3 2 2 1 0 0 3]\n",
      "[3 3 3 3 0 3 2 2]\n",
      "[3 0 0 3 2 1 0 1]\n",
      "[2 1 2 2 2 1 2 2]\n",
      "[3 0 0 0 1 0 1 1]\n",
      "[1 2 1 3 2 0 3 0]\n",
      "[1 1 2 2 1 1 0 3]\n",
      "[3 0 1 2 1 2 0 3]\n",
      "[3 3 2 1 1 3 2 2]\n",
      "[1 3 3 2 2 2 1 2]\n",
      "[2 2 0 1 2 3 1 3]\n",
      "[2 1 1 2 1 3 1 1]\n",
      "[0 0 1 1 2 3 1 2]\n",
      "[2 0 1 3 2 2 2 0]\n",
      "[1 1 1 1 0 3 1 3]\n",
      "[1 2 2 1 3 2 1 3]\n",
      "[2 1 3 3 0 1 1 2]\n",
      "[0 1 1 1 1 0 1]\n",
      "Epoch 4/10 |  val  |  Loss: 3.4355 Acc: 0.6400\n",
      "Train Epoch: 4 [0/1497 (0%)]\tLoss: 0.528920\n",
      "Train Epoch: 4 [80/1497 (5%)]\tLoss: 1.448070\n",
      "Train Epoch: 4 [160/1497 (11%)]\tLoss: 0.267336\n",
      "Train Epoch: 4 [240/1497 (16%)]\tLoss: 0.375438\n",
      "Train Epoch: 4 [320/1497 (21%)]\tLoss: 0.357660\n",
      "Train Epoch: 4 [400/1497 (27%)]\tLoss: 0.929620\n",
      "Train Epoch: 4 [480/1497 (32%)]\tLoss: 0.719687\n",
      "Train Epoch: 4 [560/1497 (37%)]\tLoss: 0.460628\n",
      "Train Epoch: 4 [640/1497 (43%)]\tLoss: 0.773001\n",
      "Train Epoch: 4 [720/1497 (48%)]\tLoss: 0.817625\n",
      "Train Epoch: 4 [800/1497 (53%)]\tLoss: 0.698847\n",
      "Train Epoch: 4 [880/1497 (59%)]\tLoss: 0.855880\n",
      "Train Epoch: 4 [960/1497 (64%)]\tLoss: 0.327614\n",
      "Train Epoch: 4 [1040/1497 (69%)]\tLoss: 0.896178\n",
      "Train Epoch: 4 [1120/1497 (74%)]\tLoss: 0.985713\n",
      "Train Epoch: 4 [1200/1497 (80%)]\tLoss: 0.854417\n",
      "Train Epoch: 4 [1280/1497 (85%)]\tLoss: 0.512988\n",
      "Train Epoch: 4 [1360/1497 (90%)]\tLoss: 1.215835\n",
      "Train Epoch: 4 [1440/1497 (96%)]\tLoss: 0.701163\n",
      "Epoch 5/10 | train |  Loss: 0.7420 Acc: 0.6994\n",
      "[0 1 2 0 0 1 0 0]\n",
      "[0 1 0 0 0 2 3 3]\n",
      "[2 0 2 3 1 1 0 0]\n",
      "[3 3 2 0 0 1 0 0]\n",
      "[2 0 0 0 2 1 0 0]\n",
      "[2 0 0 0 2 0 3 2]\n",
      "[3 2 2 2 1 2 1 2]\n",
      "[0 2 1 3 1 0 0 1]\n",
      "[3 2 3 1 1 1 0 3]\n",
      "[2 3 1 0 0 1 3 0]\n",
      "[3 0 1 0 3 2 2 0]\n",
      "[2 1 0 0 1 0 0 2]\n",
      "[0 0 0 0 1 1 2 2]\n",
      "[2 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 3]\n",
      "[3 3 0 0 0 3 0 3]\n",
      "[2 0 3 1 2 0 0 0]\n",
      "[1 1 2 1 3 2 0 0]\n",
      "[0 0 0 0 0 0 3 0]\n",
      "[0 3 0 2 0 2 2 3]\n",
      "[2 0 0 0 2 0 2 0]\n",
      "[0 0 2 2 3 2 0 3]\n",
      "[2 2 0 3 0 0 0 2]\n",
      "[3 0 0 3 2 0 2 0]\n",
      "[3 1 1 0 3 2 2 0]\n",
      "[1 0 0 2 1 2 2 2]\n",
      "[1 2 1 1 0 0 2 0]\n",
      "[3 2 0 1 1 0 2 2]\n",
      "[0 0 3 3 0 0 0 2]\n",
      "[2 3 2 2 0 0 0 2]\n",
      "[0 3 3 1 0 3 2 0]\n",
      "[3 0 0 0 0 1 0 0]\n",
      "[2 1 2 2 2 1 2 2]\n",
      "[2 0 0 0 1 0 1 0]\n",
      "[0 3 1 3 2 1 3 0]\n",
      "[1 2 2 3 1 1 0 3]\n",
      "[0 0 1 2 0 2 0 0]\n",
      "[0 3 2 1 1 3 2 2]\n",
      "[1 3 0 2 2 2 0 2]\n",
      "[2 2 0 1 2 0 0 3]\n",
      "[2 0 1 2 1 3 0 0]\n",
      "[0 0 0 1 2 0 1 2]\n",
      "[1 0 0 3 2 2 2 0]\n",
      "[1 1 0 1 0 0 0 0]\n",
      "[0 2 2 0 3 2 1 3]\n",
      "[2 1 0 3 0 0 1 3]\n",
      "[0 0 3 1 1 0 1]\n",
      "Epoch 5/10 |  val  |  Loss: 0.2192 Acc: 0.5973\n",
      "Train Epoch: 5 [0/1497 (0%)]\tLoss: 1.098656\n",
      "Train Epoch: 5 [80/1497 (5%)]\tLoss: 0.491091\n",
      "Train Epoch: 5 [160/1497 (11%)]\tLoss: 1.064088\n",
      "Train Epoch: 5 [240/1497 (16%)]\tLoss: 0.786659\n",
      "Train Epoch: 5 [320/1497 (21%)]\tLoss: 0.393591\n",
      "Train Epoch: 5 [400/1497 (27%)]\tLoss: 1.013279\n",
      "Train Epoch: 5 [480/1497 (32%)]\tLoss: 0.247374\n",
      "Train Epoch: 5 [560/1497 (37%)]\tLoss: 0.873777\n",
      "Train Epoch: 5 [640/1497 (43%)]\tLoss: 0.710637\n",
      "Train Epoch: 5 [720/1497 (48%)]\tLoss: 0.362307\n",
      "Train Epoch: 5 [800/1497 (53%)]\tLoss: 0.359956\n",
      "Train Epoch: 5 [880/1497 (59%)]\tLoss: 1.356803\n",
      "Train Epoch: 5 [960/1497 (64%)]\tLoss: 0.472852\n",
      "Train Epoch: 5 [1040/1497 (69%)]\tLoss: 0.627840\n",
      "Train Epoch: 5 [1120/1497 (74%)]\tLoss: 0.676991\n",
      "Train Epoch: 5 [1200/1497 (80%)]\tLoss: 1.299358\n",
      "Train Epoch: 5 [1280/1497 (85%)]\tLoss: 0.372035\n",
      "Train Epoch: 5 [1360/1497 (90%)]\tLoss: 1.476411\n",
      "Train Epoch: 5 [1440/1497 (96%)]\tLoss: 0.538279\n",
      "Epoch 6/10 | train |  Loss: 0.6259 Acc: 0.7562\n",
      "[2 0 2 0 2 2 0 0]\n",
      "[3 2 0 2 0 2 2 2]\n",
      "[2 2 2 2 3 1 0 0]\n",
      "[3 2 2 2 0 2 2 0]\n",
      "[2 0 2 2 2 1 1 0]\n",
      "[2 0 0 2 2 0 2 2]\n",
      "[2 2 2 2 3 2 0 2]\n",
      "[0 2 2 2 3 2 0 2]\n",
      "[2 2 3 3 2 3 3 2]\n",
      "[2 2 3 0 0 2 3 0]\n",
      "[2 0 3 0 2 2 2 0]\n",
      "[0 1 3 2 2 2 2 2]\n",
      "[0 0 2 0 1 1 2 2]\n",
      "[2 3 2 0 0 0 0 2]\n",
      "[3 0 3 1 2 0 0 2]\n",
      "[2 2 2 0 2 2 2 2]\n",
      "[2 0 3 2 2 0 2 0]\n",
      "[2 2 2 2 2 2 3 0]\n",
      "[2 3 0 2 0 1 0 0]\n",
      "[0 2 0 2 2 2 2 2]\n",
      "[2 0 0 0 2 0 2 2]\n",
      "[2 0 2 2 3 2 0 2]\n",
      "[2 2 0 2 0 0 2 2]\n",
      "[2 0 0 2 2 0 2 2]\n",
      "[3 3 0 2 2 2 2 0]\n",
      "[2 1 0 2 1 2 2 0]\n",
      "[2 2 2 1 2 3 2 2]\n",
      "[3 2 3 2 2 0 2 2]\n",
      "[0 0 3 2 0 2 0 2]\n",
      "[2 2 2 2 3 0 0 3]\n",
      "[3 2 2 2 0 2 2 2]\n",
      "[2 0 0 0 2 2 0 2]\n",
      "[2 0 2 2 2 1 2 2]\n",
      "[2 0 0 0 0 0 1 0]\n",
      "[0 2 1 2 2 0 2 0]\n",
      "[3 2 2 2 2 2 0 2]\n",
      "[2 0 2 2 2 2 0 2]\n",
      "[2 0 2 3 0 2 2 2]\n",
      "[3 2 0 2 2 2 0 2]\n",
      "[2 2 2 2 2 2 2 3]\n",
      "[2 2 1 2 3 2 0 0]\n",
      "[0 0 0 1 2 0 1 2]\n",
      "[2 0 0 2 2 2 2 0]\n",
      "[1 1 0 2 0 3 0 0]\n",
      "[0 2 2 3 2 2 2 2]\n",
      "[2 2 0 2 0 2 1 2]\n",
      "[0 0 2 0 2 0 3]\n",
      "Epoch 6/10 |  val  |  Loss: 0.0900 Acc: 0.5227\n",
      "Train Epoch: 6 [0/1497 (0%)]\tLoss: 0.376462\n",
      "Train Epoch: 6 [80/1497 (5%)]\tLoss: 0.676588\n",
      "Train Epoch: 6 [160/1497 (11%)]\tLoss: 0.843135\n",
      "Train Epoch: 6 [240/1497 (16%)]\tLoss: 0.775132\n",
      "Train Epoch: 6 [320/1497 (21%)]\tLoss: 0.290902\n",
      "Train Epoch: 6 [400/1497 (27%)]\tLoss: 1.072545\n",
      "Train Epoch: 6 [480/1497 (32%)]\tLoss: 0.799539\n",
      "Train Epoch: 6 [560/1497 (37%)]\tLoss: 0.382372\n",
      "Train Epoch: 6 [640/1497 (43%)]\tLoss: 0.221919\n",
      "Train Epoch: 6 [720/1497 (48%)]\tLoss: 0.813340\n",
      "Train Epoch: 6 [800/1497 (53%)]\tLoss: 0.965281\n",
      "Train Epoch: 6 [880/1497 (59%)]\tLoss: 0.580516\n",
      "Train Epoch: 6 [960/1497 (64%)]\tLoss: 1.187193\n",
      "Train Epoch: 6 [1040/1497 (69%)]\tLoss: 0.420560\n",
      "Train Epoch: 6 [1120/1497 (74%)]\tLoss: 0.320906\n",
      "Train Epoch: 6 [1200/1497 (80%)]\tLoss: 0.641606\n",
      "Train Epoch: 6 [1280/1497 (85%)]\tLoss: 0.898713\n",
      "Train Epoch: 6 [1360/1497 (90%)]\tLoss: 0.350881\n",
      "Train Epoch: 6 [1440/1497 (96%)]\tLoss: 0.747361\n",
      "Epoch 7/10 | train |  Loss: 0.5922 Acc: 0.7722\n",
      "[2 3 2 3 2 2 3 0]\n",
      "[3 2 1 3 3 2 3 3]\n",
      "[3 2 2 3 1 1 0 3]\n",
      "[3 2 2 2 0 3 2 2]\n",
      "[2 0 3 3 2 1 3 2]\n",
      "[2 0 0 2 3 0 2 2]\n",
      "[2 2 2 2 1 2 1 2]\n",
      "[0 2 2 3 3 2 0 1]\n",
      "[3 1 3 3 1 1 3 3]\n",
      "[2 3 1 0 2 2 3 1]\n",
      "[2 3 3 2 3 2 2 2]\n",
      "[3 1 3 3 2 0 2 2]\n",
      "[3 0 2 0 1 1 2 2]\n",
      "[2 3 1 3 3 3 0 1]\n",
      "[3 0 3 3 3 1 0 3]\n",
      "[3 2 2 0 2 3 3 3]\n",
      "[2 0 3 3 2 0 2 1]\n",
      "[1 2 2 2 3 2 3 0]\n",
      "[3 3 0 2 0 3 3 0]\n",
      "[0 3 3 2 2 2 2 3]\n",
      "[2 2 3 3 3 3 2 2]\n",
      "[3 0 2 2 3 3 3 3]\n",
      "[2 2 0 3 2 0 2 2]\n",
      "[3 3 3 2 2 3 2 2]\n",
      "[3 3 1 1 3 2 2 0]\n",
      "[2 1 0 2 3 2 2 2]\n",
      "[1 2 2 1 2 3 2 2]\n",
      "[3 2 3 1 2 1 2 2]\n",
      "[3 0 3 3 0 1 0 2]\n",
      "[2 3 2 2 3 0 0 3]\n",
      "[3 3 3 3 0 3 2 2]\n",
      "[3 0 0 3 2 2 0 1]\n",
      "[2 1 2 2 2 1 2 2]\n",
      "[2 0 3 0 0 0 3 3]\n",
      "[0 2 1 3 2 3 3 0]\n",
      "[1 2 2 2 1 2 0 3]\n",
      "[3 0 1 2 1 2 0 3]\n",
      "[3 3 3 3 3 3 2 2]\n",
      "[1 3 3 2 2 2 3 2]\n",
      "[2 2 2 1 2 3 2 3]\n",
      "[2 2 1 2 3 2 0 0]\n",
      "[0 0 2 1 2 3 1 2]\n",
      "[2 0 3 3 2 2 2 0]\n",
      "[3 1 3 1 0 3 3 3]\n",
      "[3 2 2 1 2 2 2 3]\n",
      "[2 1 3 3 0 1 1 2]\n",
      "[0 3 3 3 1 0 1]\n",
      "Epoch 7/10 |  val  |  Loss: 0.4986 Acc: 0.6133\n",
      "Train Epoch: 7 [0/1497 (0%)]\tLoss: 0.978341\n",
      "Train Epoch: 7 [80/1497 (5%)]\tLoss: 0.652597\n",
      "Train Epoch: 7 [160/1497 (11%)]\tLoss: 0.478595\n",
      "Train Epoch: 7 [240/1497 (16%)]\tLoss: 0.116443\n",
      "Train Epoch: 7 [320/1497 (21%)]\tLoss: 0.471740\n",
      "Train Epoch: 7 [400/1497 (27%)]\tLoss: 0.266755\n",
      "Train Epoch: 7 [480/1497 (32%)]\tLoss: 1.243084\n",
      "Train Epoch: 7 [560/1497 (37%)]\tLoss: 0.653455\n",
      "Train Epoch: 7 [640/1497 (43%)]\tLoss: 0.658319\n",
      "Train Epoch: 7 [720/1497 (48%)]\tLoss: 0.821642\n",
      "Train Epoch: 7 [800/1497 (53%)]\tLoss: 0.531991\n",
      "Train Epoch: 7 [880/1497 (59%)]\tLoss: 0.486536\n",
      "Train Epoch: 7 [960/1497 (64%)]\tLoss: 0.588822\n",
      "Train Epoch: 7 [1040/1497 (69%)]\tLoss: 0.208473\n",
      "Train Epoch: 7 [1120/1497 (74%)]\tLoss: 0.411377\n",
      "Train Epoch: 7 [1200/1497 (80%)]\tLoss: 0.300302\n",
      "Train Epoch: 7 [1280/1497 (85%)]\tLoss: 0.490081\n",
      "Train Epoch: 7 [1360/1497 (90%)]\tLoss: 0.188375\n",
      "Train Epoch: 7 [1440/1497 (96%)]\tLoss: 0.836656\n",
      "Epoch 8/10 | train |  Loss: 0.4803 Acc: 0.8210\n",
      "[2 0 2 3 2 1 0 0]\n",
      "[3 2 0 3 0 2 3 3]\n",
      "[3 2 2 3 2 3 0 3]\n",
      "[3 2 2 2 0 2 2 2]\n",
      "[2 0 3 2 2 3 2 2]\n",
      "[2 0 0 2 3 0 2 2]\n",
      "[3 2 3 2 3 2 0 2]\n",
      "[0 2 2 3 3 2 0 3]\n",
      "[3 2 3 3 2 3 3 3]\n",
      "[2 3 3 0 0 2 3 0]\n",
      "[2 3 3 2 3 2 2 2]\n",
      "[1 1 0 2 2 0 2 2]\n",
      "[0 0 2 0 2 3 2 2]\n",
      "[2 2 2 0 3 1 0 3]\n",
      "[0 0 0 2 2 0 0 3]\n",
      "[2 2 2 0 2 2 3 3]\n",
      "[2 0 3 3 2 0 2 0]\n",
      "[2 2 2 2 3 2 0 0]\n",
      "[3 3 0 2 0 3 3 0]\n",
      "[0 3 3 2 2 2 2 3]\n",
      "[2 2 2 0 3 0 2 2]\n",
      "[2 0 2 2 3 2 0 3]\n",
      "[2 2 0 3 0 0 2 2]\n",
      "[3 3 0 2 2 0 3 2]\n",
      "[3 3 0 1 3 3 2 0]\n",
      "[2 1 0 2 1 2 2 2]\n",
      "[2 2 2 3 2 0 2 3]\n",
      "[3 2 0 2 2 2 2 2]\n",
      "[0 0 3 3 0 2 0 2]\n",
      "[2 3 2 2 0 0 0 3]\n",
      "[3 3 3 2 0 3 2 2]\n",
      "[3 0 0 3 2 2 0 3]\n",
      "[2 0 2 2 2 3 2 2]\n",
      "[3 0 0 0 0 0 1 0]\n",
      "[0 2 0 3 2 0 3 0]\n",
      "[3 2 2 2 2 2 0 3]\n",
      "[3 0 2 2 3 2 0 3]\n",
      "[3 0 2 3 0 3 2 2]\n",
      "[1 3 3 3 2 2 0 2]\n",
      "[2 2 2 2 2 3 2 3]\n",
      "[2 2 1 2 1 2 0 0]\n",
      "[0 0 2 2 2 0 3 2]\n",
      "[2 0 0 3 2 2 2 0]\n",
      "[1 1 0 2 0 3 1 0]\n",
      "[3 2 2 1 2 2 2 2]\n",
      "[2 1 2 3 0 2 1 3]\n",
      "[0 0 3 0 2 0 3]\n",
      "Epoch 8/10 |  val  |  Loss: 1.5392 Acc: 0.5813\n",
      "Train Epoch: 8 [0/1497 (0%)]\tLoss: 1.048743\n",
      "Train Epoch: 8 [80/1497 (5%)]\tLoss: 0.857311\n",
      "Train Epoch: 8 [160/1497 (11%)]\tLoss: 0.504659\n",
      "Train Epoch: 8 [240/1497 (16%)]\tLoss: 0.295623\n",
      "Train Epoch: 8 [320/1497 (21%)]\tLoss: 0.627303\n",
      "Train Epoch: 8 [400/1497 (27%)]\tLoss: 0.429639\n",
      "Train Epoch: 8 [480/1497 (32%)]\tLoss: 1.457092\n",
      "Train Epoch: 8 [560/1497 (37%)]\tLoss: 0.388349\n",
      "Train Epoch: 8 [640/1497 (43%)]\tLoss: 0.436055\n",
      "Train Epoch: 8 [720/1497 (48%)]\tLoss: 0.618972\n",
      "Train Epoch: 8 [800/1497 (53%)]\tLoss: 0.540921\n",
      "Train Epoch: 8 [880/1497 (59%)]\tLoss: 0.235735\n",
      "Train Epoch: 8 [960/1497 (64%)]\tLoss: 0.183845\n",
      "Train Epoch: 8 [1040/1497 (69%)]\tLoss: 0.562683\n",
      "Train Epoch: 8 [1120/1497 (74%)]\tLoss: 0.273427\n",
      "Train Epoch: 8 [1200/1497 (80%)]\tLoss: 0.862921\n",
      "Train Epoch: 8 [1280/1497 (85%)]\tLoss: 0.577187\n",
      "Train Epoch: 8 [1360/1497 (90%)]\tLoss: 0.478936\n",
      "Train Epoch: 8 [1440/1497 (96%)]\tLoss: 0.773630\n",
      "Epoch 9/10 | train |  Loss: 0.4798 Acc: 0.8223\n",
      "[2 3 2 3 2 1 3 0]\n",
      "[3 3 1 3 3 2 3 3]\n",
      "[3 1 2 3 3 3 3 3]\n",
      "[3 2 2 3 0 3 0 2]\n",
      "[3 3 3 1 2 3 1 3]\n",
      "[2 3 0 3 3 0 2 2]\n",
      "[3 1 3 2 3 2 1 3]\n",
      "[0 3 3 3 3 3 0 3]\n",
      "[3 2 3 1 3 3 1 3]\n",
      "[2 3 3 0 1 2 3 1]\n",
      "[3 3 3 1 3 2 3 0]\n",
      "[3 1 3 3 3 0 3 2]\n",
      "[3 3 3 3 1 1 2 1]\n",
      "[2 3 1 3 3 1 1 1]\n",
      "[3 0 3 3 3 0 0 3]\n",
      "[3 2 1 0 2 3 3 3]\n",
      "[2 0 3 1 2 0 3 1]\n",
      "[3 2 3 3 3 3 3 0]\n",
      "[3 3 0 3 0 1 3 0]\n",
      "[0 3 3 2 1 2 2 3]\n",
      "[2 1 3 3 3 3 1 2]\n",
      "[3 0 2 1 3 3 3 3]\n",
      "[2 2 3 3 1 0 3 2]\n",
      "[3 3 3 3 2 3 3 3]\n",
      "[3 3 3 1 3 3 2 0]\n",
      "[3 1 0 2 1 2 2 1]\n",
      "[1 1 2 3 2 3 3 3]\n",
      "[3 2 3 1 3 3 3 3]\n",
      "[3 0 3 3 3 3 3 3]\n",
      "[2 3 2 2 3 0 1 3]\n",
      "[3 3 3 3 0 3 2 1]\n",
      "[3 0 1 3 2 2 3 3]\n",
      "[1 1 1 2 2 1 2 2]\n",
      "[3 0 3 0 0 0 1 3]\n",
      "[3 2 1 3 3 3 3 0]\n",
      "[3 2 3 3 3 1 0 3]\n",
      "[3 0 1 2 1 2 0 3]\n",
      "[3 3 1 3 3 3 2 2]\n",
      "[3 3 3 3 1 3 3 2]\n",
      "[2 2 2 1 2 3 1 3]\n",
      "[2 3 1 3 3 3 3 0]\n",
      "[1 0 2 3 2 3 1 3]\n",
      "[2 0 1 3 2 2 3 0]\n",
      "[1 1 3 3 1 3 1 3]\n",
      "[3 2 2 1 3 2 1 3]\n",
      "[3 1 3 3 0 3 1 3]\n",
      "[0 3 3 3 3 0 3]\n",
      "Epoch 9/10 |  val  |  Loss: 1.4498 Acc: 0.5493\n",
      "Train Epoch: 9 [0/1497 (0%)]\tLoss: 0.583577\n",
      "Train Epoch: 9 [80/1497 (5%)]\tLoss: 0.344785\n",
      "Train Epoch: 9 [160/1497 (11%)]\tLoss: 0.424667\n",
      "Train Epoch: 9 [240/1497 (16%)]\tLoss: 0.483145\n",
      "Train Epoch: 9 [320/1497 (21%)]\tLoss: 0.171308\n",
      "Train Epoch: 9 [400/1497 (27%)]\tLoss: 0.075563\n",
      "Train Epoch: 9 [480/1497 (32%)]\tLoss: 0.032419\n",
      "Train Epoch: 9 [560/1497 (37%)]\tLoss: 1.212042\n",
      "Train Epoch: 9 [640/1497 (43%)]\tLoss: 0.178490\n",
      "Train Epoch: 9 [720/1497 (48%)]\tLoss: 0.141926\n",
      "Train Epoch: 9 [800/1497 (53%)]\tLoss: 0.223123\n",
      "Train Epoch: 9 [880/1497 (59%)]\tLoss: 0.330169\n",
      "Train Epoch: 9 [960/1497 (64%)]\tLoss: 0.132502\n",
      "Train Epoch: 9 [1040/1497 (69%)]\tLoss: 0.493583\n",
      "Train Epoch: 9 [1120/1497 (74%)]\tLoss: 0.222266\n",
      "Train Epoch: 9 [1200/1497 (80%)]\tLoss: 0.476862\n",
      "Train Epoch: 9 [1280/1497 (85%)]\tLoss: 0.553490\n",
      "Train Epoch: 9 [1360/1497 (90%)]\tLoss: 0.115240\n",
      "Train Epoch: 9 [1440/1497 (96%)]\tLoss: 0.557164\n",
      "Epoch 10/10 | train |  Loss: 0.3629 Acc: 0.8804\n",
      "[2 0 2 1 1 1 0 0]\n",
      "[3 2 1 3 0 1 2 2]\n",
      "[2 2 2 3 1 1 0 1]\n",
      "[3 2 2 3 0 1 0 2]\n",
      "[2 0 3 2 2 1 1 0]\n",
      "[2 0 0 2 3 0 2 2]\n",
      "[2 2 2 2 1 2 1 2]\n",
      "[0 2 2 2 3 2 0 1]\n",
      "[3 2 3 1 1 1 1 1]\n",
      "[2 3 1 0 0 2 3 1]\n",
      "[2 0 3 2 3 2 3 1]\n",
      "[1 1 1 3 2 0 2 2]\n",
      "[0 0 0 0 1 1 2 2]\n",
      "[2 1 1 1 1 1 0 1]\n",
      "[3 0 1 1 3 2 0 3]\n",
      "[2 2 2 0 2 3 3 2]\n",
      "[2 0 3 1 2 0 1 1]\n",
      "[3 2 2 2 2 2 1 0]\n",
      "[1 3 0 3 0 1 1 0]\n",
      "[0 2 0 2 2 2 2 2]\n",
      "[2 1 0 0 2 0 2 2]\n",
      "[3 0 2 2 1 1 3 3]\n",
      "[2 2 0 3 0 0 2 2]\n",
      "[3 3 0 2 2 1 2 3]\n",
      "[1 1 1 1 2 2 2 0]\n",
      "[2 1 0 2 1 2 2 2]\n",
      "[3 2 2 1 2 3 2 2]\n",
      "[1 2 1 1 2 1 2 2]\n",
      "[0 0 3 2 0 1 0 2]\n",
      "[2 3 2 2 1 0 0 3]\n",
      "[0 2 3 3 0 3 2 2]\n",
      "[3 0 0 3 2 3 0 2]\n",
      "[2 1 2 2 2 1 2 2]\n",
      "[2 0 0 0 0 0 1 0]\n",
      "[0 2 1 3 2 0 1 0]\n",
      "[1 2 2 2 2 1 0 3]\n",
      "[2 0 1 2 2 2 0 3]\n",
      "[3 1 2 1 0 3 2 2]\n",
      "[1 3 1 2 1 2 1 2]\n",
      "[2 2 0 1 2 3 2 1]\n",
      "[2 3 1 2 1 2 0 0]\n",
      "[0 0 0 1 2 1 1 2]\n",
      "[2 0 1 3 2 2 1 0]\n",
      "[1 1 1 1 0 3 2 3]\n",
      "[0 2 2 1 2 2 1 3]\n",
      "[2 1 2 3 0 2 1 3]\n",
      "[0 0 3 1 3 0 3]\n",
      "Epoch 10/10 |  val  |  Loss: 0.0009 Acc: 0.6640\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "wandb.init(\n",
    "    project=\"wavlm_SER\",\n",
    "    config={\n",
    "        \"pretrained_model\": 'patrickvonplaten/wavlm-libri-clean-100h-base-plus',\n",
    "        'dataset': 'IEMOCAP_balanced_subset_lthresh=100000',\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 8,\n",
    "        \"learning_rate\": 0.0001, \n",
    "        \"lr_scheduler_step\": 300,\n",
    "        \"lr_scheduler_step_unit\": 'batch_iter',\n",
    "        \"lr_scheduler_gamma\": 0.9,\n",
    "        \"all_parameters\": True\n",
    "        })\n",
    "config = wandb.config\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n",
    "dataloaders_dict = {'train': train_loader, 'val': test_loader}\n",
    "\n",
    "# モデルの定義\n",
    "class SERwithWavLM(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.wavlm_config = WavLMConfig(pretrained_model)\n",
    "        self.wavlm_config.update({'num_labels':4, 'use_weighted_layer_sum':True})\n",
    "        self.wavlm = WavLMForSequenceClassification.from_pretrained(pretrained_model, config=self.wavlm_config)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.wavlm(**inputs[0], labels=inputs[1]) \n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        # Liner層の初期化\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "model = SERwithWavLM(config[\"pretrained_model\"])\n",
    "model.wavlm.classifier.apply(weights_init)\n",
    "model.to(device)\n",
    "\n",
    "'''param_to_update = []\n",
    "param_to_update_name = {}\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' in name:\n",
    "        print(name)\n",
    "        param.requires_grad = True\n",
    "        param_to_update.append(param)\n",
    "        param_to_update_name[f'{name}'] = 0.0001\n",
    "    else:\n",
    "        param.requires_grad = False'''\n",
    "\n",
    "'''wandb.config.update({\"updated_param\": param_to_update_name})'''\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=0.0001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"lr_scheduler_step\"], gamma=config[\"lr_scheduler_gamma\"]) \n",
    "\n",
    "num_epochs = config[\"epochs\"]\n",
    "\n",
    "model = train_model(model, dataloaders_dict, optimizer, None, num_epochs, log_interval=10)\n",
    "\n",
    "model_path = 'checkpoint/wavlm_IEMOCAP_5.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wavlm_summary.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10bc24d58dd64baf9875951175d53cb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13593a06989240bd8d2cca1d13d302c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16931946ca934132bc47219683486303": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "344d4d40846c48c5b23d1f2f004a6a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f605ea8772394995828669527c9e39c7",
      "placeholder": "​",
      "style": "IPY_MODEL_deb1de98e25f4fb798c9d721e4dcca04",
      "value": " 0.8382352941176459/10 [00:59&lt;05:49, 38.20s/it]"
     }
    },
    "7a2585dcff9e46d2b3e429cdfe15251b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10bc24d58dd64baf9875951175d53cb7",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13593a06989240bd8d2cca1d13d302c7",
      "value": 0.8382352941176459
     }
    },
    "96817ccf7f694652a9ee52704bc833df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c25575c795c498dad30ddb60a54992f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2aad960f4e147c39bbf4e3486ae8abf",
       "IPY_MODEL_7a2585dcff9e46d2b3e429cdfe15251b",
       "IPY_MODEL_344d4d40846c48c5b23d1f2f004a6a2c"
      ],
      "layout": "IPY_MODEL_16931946ca934132bc47219683486303"
     }
    },
    "c2843e7055024ca59738182107150ae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2aad960f4e147c39bbf4e3486ae8abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96817ccf7f694652a9ee52704bc833df",
      "placeholder": "​",
      "style": "IPY_MODEL_c2843e7055024ca59738182107150ae3",
      "value": "  8%"
     }
    },
    "deb1de98e25f4fb798c9d721e4dcca04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f605ea8772394995828669527c9e39c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
